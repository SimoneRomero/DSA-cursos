{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificar clientes de acordo com a possibilidade de pagar ou não o crédito\n",
    "\n",
    "Exemplo de utilização do algoritmo RandomForest da biblioteca Spark MLLib\n",
    "\n",
    "\n",
    "Apache Spark 2.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark session- para se trabalhar com DataFrame do Spark\n",
    "spSession = SparkSession.builder.master(\"local\").appName(\"DSA-SparkMLLib\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#carregamento do dataset para o formato RDD\n",
    "bankRDD = sc.textFile(\"data/bank.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data/bank.csv MapPartitionsRDD[1] at textFile at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#colocar dados na cache\n",
    "bankRDD.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "542"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#número de exemplos + cabeçalho\n",
    "bankRDD.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"age\";\"job\";\"marital\";\"education\";\"default\";\"balance\";\"housing\";\"loan\";\"contact\";\"day\";\"month\";\"duration\";\"campaign\";\"pdays\";\"previous\";\"poutcome\";\"y\"',\n",
       " '30;\"unemployed\";\"married\";\"primary\";\"no\";1787;\"no\";\"no\";\"cellular\";19;\"oct\";79;1;-1;0;\"unknown\";\"no\"',\n",
       " '33;\"services\";\"married\";\"secondary\";\"no\";4789;\"yes\";\"yes\";\"cellular\";11;\"may\";220;1;339;4;\"failure\";\"yes\"',\n",
       " '35;\"management\";\"single\";\"tertiary\";\"no\";1350;\"yes\";\"no\";\"cellular\";16;\"apr\";185;1;330;1;\"failure\";\"yes\"',\n",
       " '30;\"management\";\"married\";\"tertiary\";\"no\";1476;\"yes\";\"yes\";\"unknown\";3;\"jun\";199;4;-1;0;\"unknown\";\"yes\"']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bankRDD.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpeza dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "541"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remover o cabeçalho\n",
    "bankRDD2 = bankRDD.filter(lambda line: \"balance\" not in line)\n",
    "bankRDD2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['30;\"unemployed\";\"married\";\"primary\";\"no\";1787;\"no\";\"no\";\"cellular\";19;\"oct\";79;1;-1;0;\"unknown\";\"no\"',\n",
       " '33;\"services\";\"married\";\"secondary\";\"no\";4789;\"yes\";\"yes\";\"cellular\";11;\"may\";220;1;339;4;\"failure\";\"yes\"',\n",
       " '35;\"management\";\"single\";\"tertiary\";\"no\";1350;\"yes\";\"no\";\"cellular\";16;\"apr\";185;1;330;1;\"failure\";\"yes\"',\n",
       " '30;\"management\";\"married\";\"tertiary\";\"no\";1476;\"yes\";\"yes\";\"unknown\";3;\"jun\";199;4;-1;0;\"unknown\";\"yes\"',\n",
       " '59;\"blue-collar\";\"married\";\"secondary\";\"no\";0;\"yes\";\"no\";\"unknown\";5;\"may\";226;1;-1;0;\"unknown\";\"no\"']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bankRDD2.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformar os dados para valores numéricos\n",
    "def transform_to_numeric(line):\n",
    "    #remove \"\" (aspas) e faz a quebra por \";\"\n",
    "    attList = line.replace(\"\\\"\",\"\").split(\";\")\n",
    "    \n",
    "    age = float(attList[0])\n",
    "    #marital\n",
    "    single = 1.0 if attList[2] == \"single\" else 0.0\n",
    "    married = 1.0 if attList[2] == \"married\" else 0.0\n",
    "    divorced = 1.0 if attList[2] == \"divorced\" else 0.0\n",
    "    #education\n",
    "    primary = 1.0 if attList[3] == \"primary\" else 0.0\n",
    "    secondary = 1.0 if attList[3] == \"secondary\" else 0.0\n",
    "    tertiary = 1.0 if attList[3] == \"tertiary\" else 0.0\n",
    "    #outros\n",
    "    default = 0.0 if attList[4] == \"no\" else 1.0\n",
    "    balance = float(attList[5])\n",
    "    housing_loan = 0.0 if attList[6] == \"no\" else 1.0\n",
    "    loan = 0.0 if attList[7] == \"no\" else 1.0\n",
    "    outcome = 0.0 if attList[16] == \"no\" else 1.0\n",
    "    \n",
    "    #linhas com os objetos transformados que farão parte da análise\n",
    "    linhas = Row(OUTCOME = outcome, AGE = age, SINGLE = single, MARRIED = married, DIVORCED = divorced,\n",
    "                 PRIMARY = primary, SECONDARY = secondary, TERTIARY = tertiary, DEFAULT = default, \n",
    "                 BALANCE = balance, LOAN = loan, HOUSING_LOAN = housing_loan)\n",
    "    \n",
    "    return linhas\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(AGE=30.0, BALANCE=1787.0, DEFAULT=0.0, DIVORCED=0.0, HOUSING_LOAN=0.0, LOAN=0.0, MARRIED=1.0, OUTCOME=0.0, PRIMARY=1.0, SECONDARY=0.0, SINGLE=0.0, TERTIARY=0.0),\n",
       " Row(AGE=33.0, BALANCE=4789.0, DEFAULT=0.0, DIVORCED=0.0, HOUSING_LOAN=1.0, LOAN=1.0, MARRIED=1.0, OUTCOME=1.0, PRIMARY=0.0, SECONDARY=1.0, SINGLE=0.0, TERTIARY=0.0),\n",
       " Row(AGE=35.0, BALANCE=1350.0, DEFAULT=0.0, DIVORCED=0.0, HOUSING_LOAN=1.0, LOAN=0.0, MARRIED=0.0, OUTCOME=1.0, PRIMARY=0.0, SECONDARY=0.0, SINGLE=1.0, TERTIARY=1.0),\n",
       " Row(AGE=30.0, BALANCE=1476.0, DEFAULT=0.0, DIVORCED=0.0, HOUSING_LOAN=1.0, LOAN=1.0, MARRIED=1.0, OUTCOME=1.0, PRIMARY=0.0, SECONDARY=0.0, SINGLE=0.0, TERTIARY=1.0),\n",
       " Row(AGE=59.0, BALANCE=0.0, DEFAULT=0.0, DIVORCED=0.0, HOUSING_LOAN=1.0, LOAN=0.0, MARRIED=1.0, OUTCOME=0.0, PRIMARY=0.0, SECONDARY=1.0, SINGLE=0.0, TERTIARY=0.0)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#aplicando a função de limpeza ao conjunto de dados\n",
    "bankRDD3 = bankRDD2.map(transform_to_numeric)\n",
    "bankRDD3.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise exploratória de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converter para Dataframe\n",
    "bankDF = spSession.createDataFrame(bankRDD3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(bankDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+--------------------+-------------------+------------------+-------------------+------------------+-------------------+------------------+------------------+------------------+------------------+\n",
      "|summary|               AGE|           BALANCE|             DEFAULT|           DIVORCED|      HOUSING_LOAN|               LOAN|           MARRIED|            OUTCOME|           PRIMARY|         SECONDARY|            SINGLE|          TERTIARY|\n",
      "+-------+------------------+------------------+--------------------+-------------------+------------------+-------------------+------------------+-------------------+------------------+------------------+------------------+------------------+\n",
      "|  count|               541|               541|                 541|                541|               541|                541|               541|                541|               541|               541|               541|               541|\n",
      "|   mean| 41.26987060998152|1444.7818853974122|0.022181146025878003|0.10905730129390019|0.5693160813308688|0.16266173752310537|0.6155268022181146| 0.3974121996303142|0.1534195933456562|0.4953789279112754|0.2754158964879852|0.3142329020332717|\n",
      "| stddev|10.555374170161665|2423.2722735171924|  0.1474086424402979| 0.3119995822161848|0.4956302515019386|0.36939832735881994|0.4869207382098541|0.48981549262335145| 0.360725025449802|0.5004413742994283|0.4471370479760759|0.4646392600205975|\n",
      "|    min|              19.0|           -1206.0|                 0.0|                0.0|               0.0|                0.0|               0.0|                0.0|               0.0|               0.0|               0.0|               0.0|\n",
      "|    max|              78.0|           16873.0|                 1.0|                1.0|               1.0|                1.0|               1.0|                1.0|               1.0|               1.0|               1.0|               1.0|\n",
      "+-------+------------------+------------------+--------------------+-------------------+------------------+-------------------+------------------+-------------------+------------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#estatística descritiva\n",
    "bankDF.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlação da variável OUTCOME com AGE -0.1823210432736525\n",
      "correlação da variável OUTCOME com BALANCE 0.036574866119976804\n",
      "correlação da variável OUTCOME com DEFAULT -0.04536965206737378\n",
      "correlação da variável OUTCOME com DIVORCED -0.07812659940926987\n",
      "correlação da variável OUTCOME com HOUSING_LOAN 0.05032284653513401\n",
      "correlação da variável OUTCOME com LOAN -0.030420586112717318\n",
      "correlação da variável OUTCOME com MARRIED -0.3753241299133561\n",
      "correlação da variável OUTCOME com OUTCOME 1.0\n",
      "correlação da variável OUTCOME com PRIMARY -0.12561548832677982\n",
      "correlação da variável OUTCOME com SECONDARY 0.026392774894072973\n",
      "correlação da variável OUTCOME com SINGLE 0.46323284934360515\n",
      "correlação da variável OUTCOME com TERTIARY 0.08494840766635618\n"
     ]
    }
   ],
   "source": [
    "#correlação entre as variáveis\n",
    "for i in bankDF.columns:\n",
    "    if not(isinstance(bankDF.select(i).take(1)[0][0], str)):\n",
    "        print(\"correlação da variável OUTCOME com\", i, bankDF.stat.corr('OUTCOME', i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criação do LabeledPoint (target, Vector[features]) - formato requerido pelo Spark\n",
    "def transform_var(row):\n",
    "    obj = (row[\"OUTCOME\"], Vectors.dense([row[\"AGE\"], row[\"BALANCE\"], row[\"DEFAULT\"], row[\"DIVORCED\"], \n",
    "                                          row[\"HOUSING_LOAN\"], row[\"LOAN\"], row[\"MARRIED\"], row[\"PRIMARY\"], \n",
    "                                          row[\"SECONDARY\"], row[\"SINGLE\"], row[\"TERTIARY\"]]))\n",
    "    \n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converte o DataFrame em RDD novamente para poder executar a função\n",
    "bankRDD4 = bankDF.rdd.map(transform_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0,\n",
       "  DenseVector([30.0, 1787.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0])),\n",
       " (1.0,\n",
       "  DenseVector([33.0, 4789.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0])),\n",
       " (1.0,\n",
       "  DenseVector([35.0, 1350.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0])),\n",
       " (1.0,\n",
       "  DenseVector([30.0, 1476.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0])),\n",
       " (0.0, DenseVector([59.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0]))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bankRDD4.collect()\n",
    "bankRDD4.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[30.0,1787.0,0.0,...|  0.0|\n",
      "|[33.0,4789.0,0.0,...|  1.0|\n",
      "|[35.0,1350.0,0.0,...|  1.0|\n",
      "|[30.0,1476.0,0.0,...|  1.0|\n",
      "|[59.0,0.0,0.0,0.0...|  0.0|\n",
      "|[35.0,747.0,0.0,0...|  1.0|\n",
      "|[36.0,307.0,0.0,0...|  1.0|\n",
      "|[39.0,147.0,0.0,0...|  0.0|\n",
      "|[41.0,221.0,0.0,0...|  0.0|\n",
      "|[43.0,-88.0,0.0,0...|  1.0|\n",
      "+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#converte para DataFrame\n",
    "bankDF_1 = spSession.createDataFrame(bankRDD4, [\"label\", \"features\"])\n",
    "bankDF_1.select(\"features\", \"label\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#duplicação do DateFrame para aplicar um passo diferente e realizar a comparação\n",
    "bankDF_2 = bankDF_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(label=0.0, features=DenseVector([30.0, 1787.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0]), indexed=0.0),\n",
       " Row(label=1.0, features=DenseVector([33.0, 4789.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0]), indexed=1.0),\n",
       " Row(label=1.0, features=DenseVector([35.0, 1350.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]), indexed=1.0),\n",
       " Row(label=1.0, features=DenseVector([30.0, 1476.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0]), indexed=1.0),\n",
       " Row(label=0.0, features=DenseVector([59.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0]), indexed=0.0)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Indexação é pré-requisito para Decision Trees\n",
    "stringIndexer = StringIndexer(inputCol = \"label\", outputCol = \"indexed\")\n",
    "si_model = stringIndexer.fit(bankDF_1)\n",
    "obj_comum = si_model.transform(bankDF_1)\n",
    "#obj_comum.collect()\n",
    "obj_comum.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------------------------------------------------+\n",
      "|label|pcaFeatures                                                  |\n",
      "+-----+-------------------------------------------------------------+\n",
      "|0.0  |[-1787.018896688212,28.860399462744468,-0.1280147985324101]  |\n",
      "|1.0  |[-4789.020151899341,29.910671811919972,-1.1873535094324654]  |\n",
      "|1.0  |[-1350.0221889042236,34.089813318413796,0.7195970243045985]  |\n",
      "|1.0  |[-1476.0189274234879,29.0402338703401,0.16333904159114176]   |\n",
      "|0.0  |[-0.03786531116986686,58.977608630868865,-0.9375316432593557]|\n",
      "|1.0  |[-747.02233755074,34.48658287707456,0.8977247669235038]      |\n",
      "|1.0  |[-307.02304514047654,35.78871235524398,0.28043105820705017]  |\n",
      "|0.0  |[-147.0249882455921,38.88983490904783,-1.0046260851665119]   |\n",
      "|0.0  |[-221.02627459762581,40.842288730459394,0.29813543281478216] |\n",
      "|1.0  |[87.97241072606795,43.051283841804064,-0.2932102577592304]   |\n",
      "|0.0  |[-9374.023079005105,32.96339467956594,-1.1790049813332166]   |\n",
      "|0.0  |[-264.0275333657839,42.8133579150793,-0.9939739758464012]    |\n",
      "|0.0  |[-1109.0229030659693,35.28305983496013,0.4320060372934725]   |\n",
      "|1.0  |[-502.0127362603077,19.64827941416095,-0.443610672731902]    |\n",
      "|1.0  |[-360.01978367820027,30.756053153051912,-1.1100825156806227] |\n",
      "|0.0  |[-194.02563989217353,39.86979887980532,0.38645720681410084]  |\n",
      "|0.0  |[-4073.035119407738,53.372011252748045,-0.8574219700169146]  |\n",
      "|1.0  |[-2317.023273478519,35.46805136326498,0.7077535517979201]    |\n",
      "|0.0  |[220.983921442678,25.112999244301857,0.1892162441772912]     |\n",
      "|1.0  |[-132.01987656440713,30.911593367465947,-0.8633373452616363] |\n",
      "+-----+-------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Vamos comparar o resultado do algoritmo RandomForest com e sem PCA, por isso, vamos criar uma versão do dataset\n",
    "#usando PCA com 3 componentes\n",
    "bankPCA = PCA(k = 3, inputCol = \"features\", outputCol = \"pcaFeatures\")\n",
    "pcaModel = bankPCA.fit(bankDF_2)\n",
    "pcaResult = pcaModel.transform(bankDF_2).select(\"label\", \"pcaFeatures\")\n",
    "pcaResult.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(label=0.0, pcaFeatures=DenseVector([-1787.0189, 28.8604, -0.128]), indexed=0.0),\n",
       " Row(label=1.0, pcaFeatures=DenseVector([-4789.0202, 29.9107, -1.1874]), indexed=1.0),\n",
       " Row(label=1.0, pcaFeatures=DenseVector([-1350.0222, 34.0898, 0.7196]), indexed=1.0),\n",
       " Row(label=1.0, pcaFeatures=DenseVector([-1476.0189, 29.0402, 0.1633]), indexed=1.0),\n",
       " Row(label=0.0, pcaFeatures=DenseVector([-0.0379, 58.9776, -0.9375]), indexed=0.0)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#é necessário fazer a Indexação nesse conjunto também\n",
    "stringIndexer = StringIndexer(inputCol = \"label\", outputCol = \"indexed\")\n",
    "si_model = stringIndexer.fit(pcaResult)\n",
    "obj_pca = si_model.transform(pcaResult)\n",
    "#obj_pca.collect()\n",
    "obj_pca.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dados de treino e teste para versão sem PCA\n",
    "(dados_treino_comum, dados_teste_comum) = obj_comum.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "394"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_treino_comum.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_teste_comum.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando o modelo\n",
    "rfClassifer = RandomForestClassifier(labelCol = \"indexed\", featuresCol = \"features\")\n",
    "modelo_comum = rfClassifer.fit(dados_treino_comum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(prediction=0.0, indexed=0.0, label=0.0, features=DenseVector([27.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0])),\n",
       " Row(prediction=0.0, indexed=0.0, label=0.0, features=DenseVector([31.0, 171.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0])),\n",
       " Row(prediction=0.0, indexed=0.0, label=0.0, features=DenseVector([32.0, 217.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0])),\n",
       " Row(prediction=0.0, indexed=0.0, label=0.0, features=DenseVector([32.0, 948.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0])),\n",
       " Row(prediction=0.0, indexed=0.0, label=0.0, features=DenseVector([32.0, 1031.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0])),\n",
       " Row(prediction=0.0, indexed=0.0, label=0.0, features=DenseVector([32.0, 2349.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0])),\n",
       " Row(prediction=0.0, indexed=0.0, label=0.0, features=DenseVector([32.0, 2693.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0])),\n",
       " Row(prediction=0.0, indexed=0.0, label=0.0, features=DenseVector([33.0, -988.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0])),\n",
       " Row(prediction=0.0, indexed=0.0, label=0.0, features=DenseVector([33.0, -204.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0])),\n",
       " Row(prediction=0.0, indexed=0.0, label=0.0, features=DenseVector([34.0, 20.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0]))]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Previsões com dados de teste\n",
    "predictions_comum = modelo_comum.transform(dados_teste_comum)\n",
    "predictions_comum.select(\"prediction\", \"indexed\", \"label\", \"features\").take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7687074829931972"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Avaliando a acurácia\n",
    "evaluator_comum = MulticlassClassificationEvaluator(predictionCol = \"prediction\", labelCol = \"indexed\", metricName = \"accuracy\")\n",
    "evaluator_comum.evaluate(predictions_comum)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-----+\n",
      "|indexed|prediction|count|\n",
      "+-------+----------+-----+\n",
      "|    1.0|       1.0|   31|\n",
      "|    0.0|       1.0|    4|\n",
      "|    1.0|       0.0|   30|\n",
      "|    0.0|       0.0|   82|\n",
      "+-------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "predictions_comum.groupBy(\"indexed\", \"prediction\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning com PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados de Treino e de Teste\n",
    "(dados_treino_pca, dados_teste_pca) = obj_pca.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "402"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_treino_pca.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_teste_pca.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfClassifer_pca = RandomForestClassifier(labelCol = \"indexed\", featuresCol = \"pcaFeatures\")\n",
    "modelo_pca = rfClassifer_pca.fit(dados_treino_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(prediction=0.0, indexed=0.0, label=0.0, pcaFeatures=DenseVector([-5426.0252, 37.4992, 0.1998])),\n",
       " Row(prediction=0.0, indexed=0.0, label=0.0, pcaFeatures=DenseVector([-4073.0351, 53.372, -0.8574])),\n",
       " Row(prediction=0.0, indexed=0.0, label=0.0, pcaFeatures=DenseVector([-4030.0229, 34.3965, -1.0844])),\n",
       " Row(prediction=0.0, indexed=0.0, label=0.0, pcaFeatures=DenseVector([-4012.0313, 47.4138, 0.4222])),\n",
       " Row(prediction=0.0, indexed=0.0, label=0.0, pcaFeatures=DenseVector([-3762.0275, 41.5764, 0.4076])),\n",
       " Row(prediction=0.0, indexed=0.0, label=0.0, pcaFeatures=DenseVector([-2843.0225, 34.1634, -0.5605])),\n",
       " Row(prediction=0.0, indexed=0.0, label=0.0, pcaFeatures=DenseVector([-2693.02, 30.2569, -1.0753])),\n",
       " Row(prediction=1.0, indexed=0.0, label=0.0, pcaFeatures=DenseVector([-2349.0201, 30.4879, 0.3957])),\n",
       " Row(prediction=0.0, indexed=0.0, label=0.0, pcaFeatures=DenseVector([-1981.0227, 34.7223, -0.8822])),\n",
       " Row(prediction=0.0, indexed=0.0, label=0.0, pcaFeatures=DenseVector([-1972.0214, 32.72, 0.2425]))]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Previsões com dados de teste\n",
    "predictions_pca = modelo_pca.transform(dados_teste_pca)\n",
    "predictions_pca.select(\"prediction\", \"indexed\", \"label\", \"pcaFeatures\").take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7122302158273381"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Avaliando a acurácia\n",
    "evaluator_pca = MulticlassClassificationEvaluator(predictionCol = \"prediction\", labelCol = \"indexed\", metricName = \"accuracy\")\n",
    "evaluator_pca.evaluate(predictions_pca)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-----+\n",
      "|indexed|prediction|count|\n",
      "+-------+----------+-----+\n",
      "|    1.0|       1.0|   26|\n",
      "|    0.0|       1.0|    8|\n",
      "|    1.0|       0.0|   32|\n",
      "|    0.0|       0.0|   73|\n",
      "+-------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "predictions_pca.groupBy(\"indexed\", \"prediction\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo sem PCA: 0.7687074829931972\n",
      "Acurácia do modelo com PCA: 0.7122302158273381\n"
     ]
    }
   ],
   "source": [
    "#comapração dos resultados\n",
    "\n",
    "print(\"Acurácia do modelo sem PCA:\", evaluator_comum.evaluate(predictions_comum))\n",
    "print(\"Acurácia do modelo com PCA:\", evaluator_pca.evaluate(predictions_pca))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A aplicação do algoritmo PCA para converter as features em 3 componentes apresentou resultados inferiores à utilização de todas as 11 features selecionadas. Talvez, a utilização de apenas 3 componentes não tenha sido suficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
